{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import sklearn.datasets\n",
    "import requests\n",
    "import json\n",
    "from interpret.blackbox import ShapKernel\n",
    "from interpret import show\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the california house pricing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_price_dataset = sklearn.datasets.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset into the pandas Dataframe\n",
    "house_price_dataframe = pd.DataFrame(house_price_dataset.data, columns=house_price_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the first 5 rows of the dataframe\n",
    "house_price_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the target (price) column to the dataframe\n",
    "house_price_dataframe['price'] = house_price_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the first 5 rows of the dataframe\n",
    "house_price_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the number of rows and columns in the dataframe\n",
    "house_price_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_price_dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_price_dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand the correlation between the various features in the dataset\n",
    "\n",
    "1. Positive Correlation\n",
    "2. Negative Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = house_price_dataframe.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing a heatmap to understand the correlation between the columns\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(correlation, cbar=True, square=True, fmt='.1f', annot=True, annot_kws={'size':8}, cmap='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house_price_dataframe.drop(['price'], axis=1)\n",
    "Y = house_price_dataframe['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training ::: \n",
    "XGBoost Regressor model for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(xgbModel,X_train, Y_train):\n",
    "    xgbModel = xgbModel.fit(X_train, Y_train)\n",
    "    \n",
    "    train_acc = xgbModel.score(X_train, Y_train)\n",
    "    mlflow.log_metric('train_accuracy', train_acc)\n",
    "    \n",
    "    \n",
    "    print(f'Train Accuracy: {train_acc:.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(xgbModel, X_test, Y_test):\n",
    "    preds = xgbModel.predict(X_test)\n",
    "\n",
    "    # Calculate regression metrics\n",
    "    mse = mean_squared_error(Y_test, preds)\n",
    "    mae = mean_absolute_error(Y_test, preds)\n",
    "    r2 = r2_score(Y_test, preds)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric('mean_squared_error', mse)\n",
    "    mlflow.log_metric('mean_absolute_error', mae)\n",
    "    mlflow.log_metric('r2_score', r2)\n",
    "\n",
    "    print(f'Mean Squared Error: {mse:.3f}')\n",
    "    print(f'Mean Absolute Error: {mae:.3f}')\n",
    "    print(f'R squared: {r2:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "xgbModel = XGBRegressor()\n",
    "\n",
    "mlflow.set_experiment('House_prediction_XGBRegressor')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    train(xgbModel, X_train, Y_train)\n",
    "    evaluate(xgbModel, X_test,Y_test)\n",
    "    \n",
    "    mlflow.sklearn.log_model(xgbModel,'XGBRegressor_model')\n",
    "    print('Model run: ',mlflow.active_run().info.run_uuid)\n",
    "mlflow.end_run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance using ShapKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = ShapKernel(predict_fn=xgbModel.predict, data=X_train, model=xgbModel)\n",
    "# You may use a subset of your data for faster computation\n",
    "X_explain = X_train.sample(100)  # Adjust the sample size as needed\n",
    "\n",
    "# Generate explanations\n",
    "shap_values = explainer.explain_local(X_explain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(shap_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation :: Prediction on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy for prediction on training data\n",
    "training_data_prediction = xgbModel.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy for prediction on test data\n",
    "test_data_prediction = xgbModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the actual prices and predicted prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_train, training_data_prediction)\n",
    "plt.xlabel(\"Actual Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "plt.title(\"Actual Prices vs Predicted Prices\")\n",
    "plt.show()\n",
    "\n",
    "#Data points that are close to eachother indicate that the price predicted is very close to the price in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.sklearn.load_model(\"runs:/ea23496ff8f24006bed32755dbf5e78a/XGBRegressor_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying a loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature names as they were used in training\n",
    "feature_names = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
    "\n",
    "# Create a new observation with fictitious values for each feature\n",
    "new_observation = [[8, 41, 6, 1, 322, 2.5, 37.88, -122.23]]\n",
    "\n",
    "# Create a DataFrame for the new observation\n",
    "input_data = pd.DataFrame(new_observation, columns=feature_names)\n",
    "\n",
    "# Now you can use the loaded_model to predict this new observation\n",
    "prediction = loaded_model.predict(input_data)\n",
    "print(\"Predicted value:\", prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serving a model locally and querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "url = 'http://127.0.0.1:4000/invocations'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "data = {\n",
    "    \"dataframe_split\": {\n",
    "        \"columns\": [\"MedInc\", \"HouseAge\", \"AveRooms\", \"AveBedrms\", \"Population\", \"AveOccup\", \"Latitude\", \"Longitude\"],\n",
    "        \"data\": [[8.3252, 41.0, 6.984127, 1.02381, 322.0, 2.555556, 37.88, -122.23]]\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    predicted_value = response.json()['predictions'][0]\n",
    "    print('Predicted value: ', predicted_value)\n",
    "else:\n",
    "    print(\"Failed to fetch response:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying a model deployed to GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "url = 'http://34.70.25.140:5000/invocations'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "data = {\n",
    "    \"dataframe_split\": {\n",
    "        \"columns\": [\"MedInc\", \"HouseAge\", \"AveRooms\", \"AveBedrms\", \"Population\", \"AveOccup\", \"Latitude\", \"Longitude\"],\n",
    "        \"data\": [[4.3252, 31.0, 6.984127, 1.02381, 322.0, 2.555556, 37.88, -122.23]]\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    predicted_value = response.json()['predictions'][0]\n",
    "    print('Predicted value: ', predicted_value)\n",
    "else:\n",
    "    print(\"Failed to fetch response:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying model running on Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlflow models build-docker --model-uri runs:/RUN ID/ModelName -n house-price-pred --enable-mlserver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "docker run -p 4000:8080 house-price-pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "url = 'http://0.0.0.0:4000/invocations'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "data = {\n",
    "    \"dataframe_split\": {\n",
    "        \"columns\": [\"MedInc\", \"HouseAge\", \"AveRooms\", \"AveBedrms\", \"Population\", \"AveOccup\", \"Latitude\", \"Longitude\"],\n",
    "        \"data\": [[4.3252, 31.0, 6.984127, 1.02381, 322.0, 2.555556, 37.88, -122.23]]\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    predicted_value = response.json()['predictions'][0]\n",
    "    print('Predicted value: ', predicted_value)\n",
    "else:\n",
    "    print(\"Failed to fetch response:\", response.status_code, response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
